{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71b8a6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "import time\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device\n",
    "\n",
    "data_augmentation = True\n",
    "batch_size_var = 1024\n",
    "batch_norm_var = True\n",
    "\n",
    "num_epochs = 100\n",
    "early_stop_thresh = 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365f09af",
   "metadata": {},
   "source": [
    "## Data augmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8026c8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Yes data augmentation\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "\n",
    "# Original transformation\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "trainset = datasets.CIFAR10(root='~/.pytorch/CIFAR10', train=True, download=True, transform=transform)\n",
    "testset = datasets.CIFAR10(root='~/.pytorch/CIFAR10', train=False, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size_var, shuffle=True)\n",
    "test_loader = DataLoader(testset, batch_size=batch_size_var, shuffle=False)\n",
    "\n",
    "# Data augmentation transformation\n",
    "augmentation_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(32),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "# Create a new dataset with augmented images\n",
    "augmented_dataset = datasets.CIFAR10(root='~/.pytorch/CIFAR10', train=True, download=True, transform=augmentation_transform)\n",
    "\n",
    "# Concatenate the original trainset with the augmented dataset\n",
    "combined_trainset = ConcatDataset([trainset, augmented_dataset])\n",
    "\n",
    "# Create DataLoader for the combined training set only if we want it\n",
    "if (data_augmentation):\n",
    "    train_loader = DataLoader(combined_trainset, batch_size=batch_size_var, shuffle=True)\n",
    "    print(\"Yes data augmentation\")\n",
    "else:\n",
    "    print(\"No dat augmentation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a462b106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 3, 32, 32]) torch.Size([1024])\n",
      "Original Trainset Size: 50000\n",
      "Augmented Trainset Size: 50000\n",
      "Combined Trainset Size: 100000\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_loader:\n",
    "  print(images.size(), labels.size())\n",
    "  break\n",
    "    \n",
    "    \n",
    "# Compare sizes of the original trainset and the augmented combined trainset\n",
    "original_trainset_size = len(trainset)\n",
    "augmented_trainset_size = len(augmented_dataset)\n",
    "combined_trainset_size = len(combined_trainset)\n",
    "\n",
    "print(f\"Original Trainset Size: {original_trainset_size}\")\n",
    "print(f\"Augmented Trainset Size: {augmented_trainset_size}\")\n",
    "print(f\"Combined Trainset Size: {combined_trainset_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44095d6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get a batch of data\n",
    "data_iter = iter(train_loader)\n",
    "images, labels = next(data_iter)\n",
    "\n",
    "# Transformation for visualization (undo normalization)\n",
    "inv_normalize = transforms.Normalize(\n",
    "    mean=[-mean[0] / std[0], -mean[1] / std[1], -mean[2] / std[2]],\n",
    "    std=[1 / std[0], 1 / std[1], 1 / std[2]]\n",
    ")\n",
    "\n",
    "\n",
    "# Function to display an image\n",
    "def show_image(img, title):\n",
    "    img = inv_normalize(img)\n",
    "    img = torch.clamp(img, 0, 1)  # Clip values to stay within valid range\n",
    "    plt.imshow(img.permute(1, 2, 0))\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Display the first image from the batch\n",
    "show_image(images[0], title=f\"Label: {labels[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23214247",
   "metadata": {},
   "source": [
    "## Model design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69c13f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using batch norm\n",
      "Total trainable parameters in the reduced model: 25418\n"
     ]
    }
   ],
   "source": [
    "class CustomCNNCifar(nn.Module):\n",
    "    def __init__(self, num_classes=10, batch_norm = True):\n",
    "        super(CustomCNNCifar, self).__init__()\n",
    "        self.batch_norm = batch_norm\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3, stride=2, padding=1, padding_mode='zeros')\n",
    "        #16x16x 8\n",
    "        if self.batch_norm:\n",
    "            self.bn1 = nn.BatchNorm2d(8)\n",
    "        self.relu1 = nn.LeakyReLU()\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=2, padding=1, padding_mode='zeros')\n",
    "        #8x8x16\n",
    "        if self.batch_norm:\n",
    "            self.bn2 = nn.BatchNorm2d(16)\n",
    "        self.relu2 = nn.LeakyReLU()\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=2, padding=1, padding_mode='zeros')\n",
    "        #4x4x32\n",
    "        if self.batch_norm:\n",
    "            self.bn3 = nn.BatchNorm2d(32)\n",
    "        self.relu3 = nn.LeakyReLU()\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=2, padding=1, padding_mode='zeros')\n",
    "        #2x2x64\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2) \n",
    "        #1x1x64\n",
    "        if self.batch_norm:\n",
    "            self.bn4 = nn.BatchNorm2d(64)\n",
    "        self.relu4 = nn.LeakyReLU()\n",
    "\n",
    "        self.flatten = nn.Flatten()        \n",
    "                \n",
    "        self.fc1 = nn.Linear(64, num_classes)\n",
    "       \n",
    "        self.log_softmax = nn.LogSoftmax(dim=1)  # Softmax activation for classification\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        if self.batch_norm:\n",
    "            x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        if self.batch_norm:\n",
    "            x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        if self.batch_norm:\n",
    "            x = self.bn3(x)\n",
    "        x = self.relu3(x)\n",
    "        \n",
    "        x = self.conv4(x)\n",
    "        if self.batch_norm:\n",
    "            x = self.bn4(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.relu4(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        x = self.log_softmax(x)  # Apply softmax for classification\n",
    "        return x\n",
    "\n",
    "# Create an instance of the SimpleCNNReduced model\n",
    "model = CustomCNNCifar(num_classes=10, batch_norm = batch_norm_var)\n",
    "if(batch_norm_var):\n",
    "    print(\"Using batch norm\")\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# Calculate the total number of trainable parameters\n",
    "total_params_reduced = count_parameters(model)\n",
    "print(f\"Total trainable parameters in the reduced model: {total_params_reduced}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa3796ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomCNNCifar(\n",
      "  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): LeakyReLU(negative_slope=0.01)\n",
      "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): LeakyReLU(negative_slope=0.01)\n",
      "  (conv3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu3): LeakyReLU(negative_slope=0.01)\n",
      "  (conv4): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu4): LeakyReLU(negative_slope=0.01)\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (log_softmax): LogSoftmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d30818",
   "metadata": {},
   "source": [
    "## Use early stopping to prevent overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce326464",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch(1/100)\n",
      "Training loss : 1.839875457238178\n",
      "Validation loss : 1.5561207294464112\n",
      "Checkpointing new best model in epoch 1\n",
      "Epoch(2/100)\n",
      "Training loss : 1.5625510094117145\n",
      "Validation loss : 1.355291473865509\n",
      "Checkpointing new best model in epoch 2\n",
      "Epoch(3/100)\n",
      "Training loss : 1.466362106556795\n",
      "Validation loss : 1.2863093614578247\n",
      "Checkpointing new best model in epoch 3\n",
      "Epoch(4/100)\n",
      "Training loss : 1.4042760121579072\n",
      "Validation loss : 1.2252084136009216\n",
      "Checkpointing new best model in epoch 4\n",
      "Epoch(5/100)\n",
      "Training loss : 1.3595500539760201\n",
      "Validation loss : 1.197614812850952\n",
      "Checkpointing new best model in epoch 5\n",
      "Epoch(6/100)\n",
      "Training loss : 1.3189682790211268\n",
      "Validation loss : 1.1704347133636475\n",
      "Checkpointing new best model in epoch 6\n",
      "Epoch(7/100)\n",
      "Training loss : 1.2863960266113281\n",
      "Validation loss : 1.136547613143921\n",
      "Checkpointing new best model in epoch 7\n",
      "Epoch(8/100)\n",
      "Training loss : 1.2591474956395674\n",
      "Validation loss : 1.1367436289787292\n",
      "Epoch(9/100)\n",
      "Training loss : 1.2320684717625987\n",
      "Validation loss : 1.1037190318107606\n",
      "Checkpointing new best model in epoch 9\n",
      "Epoch(10/100)\n",
      "Training loss : 1.2133714495872965\n",
      "Validation loss : 1.0916850566864014\n",
      "Checkpointing new best model in epoch 10\n",
      "Epoch(11/100)\n",
      "Training loss : 1.1957463147688885\n",
      "Validation loss : 1.078599786758423\n",
      "Checkpointing new best model in epoch 11\n",
      "Epoch(12/100)\n",
      "Training loss : 1.1773758275168282\n",
      "Validation loss : 1.0593111515045166\n",
      "Checkpointing new best model in epoch 12\n",
      "Epoch(13/100)\n",
      "Training loss : 1.1629446282678721\n",
      "Validation loss : 1.0370443046092988\n",
      "Checkpointing new best model in epoch 13\n",
      "Epoch(14/100)\n",
      "Training loss : 1.152968013773159\n",
      "Validation loss : 1.0364394545555116\n",
      "Checkpointing new best model in epoch 14\n",
      "Epoch(15/100)\n",
      "Training loss : 1.13900184023137\n",
      "Validation loss : 1.0304361701011657\n",
      "Checkpointing new best model in epoch 15\n",
      "Epoch(16/100)\n",
      "Training loss : 1.129023087267973\n",
      "Validation loss : 1.0191297829151154\n",
      "Checkpointing new best model in epoch 16\n",
      "Epoch(17/100)\n",
      "Training loss : 1.1181757085177364\n",
      "Validation loss : 1.027322882413864\n",
      "Epoch(18/100)\n",
      "Training loss : 1.1150099708109487\n",
      "Validation loss : 1.0110143303871155\n",
      "Checkpointing new best model in epoch 18\n",
      "Epoch(19/100)\n",
      "Training loss : 1.103009554804588\n",
      "Validation loss : 1.0052643120288849\n",
      "Checkpointing new best model in epoch 19\n",
      "Epoch(20/100)\n",
      "Training loss : 1.0957475754679467\n",
      "Validation loss : 1.0113774359226226\n",
      "Epoch(21/100)\n",
      "Training loss : 1.0878936697025687\n",
      "Validation loss : 1.0195423662662506\n",
      "Epoch(22/100)\n",
      "Training loss : 1.083859357298637\n",
      "Validation loss : 1.0005472540855407\n",
      "Checkpointing new best model in epoch 22\n",
      "Epoch(23/100)\n",
      "Training loss : 1.0773874916592423\n",
      "Validation loss : 1.00107262134552\n",
      "Epoch(24/100)\n",
      "Training loss : 1.071131568173973\n",
      "Validation loss : 0.9874973714351654\n",
      "Checkpointing new best model in epoch 24\n",
      "Epoch(25/100)\n",
      "Training loss : 1.068689573176053\n",
      "Validation loss : 0.9903904020786285\n",
      "Epoch(26/100)\n",
      "Training loss : 1.0598826852380012\n",
      "Validation loss : 0.9845195114612579\n",
      "Checkpointing new best model in epoch 26\n",
      "Epoch(27/100)\n",
      "Training loss : 1.0602812323035027\n",
      "Validation loss : 0.9923023104667663\n",
      "Epoch(28/100)\n",
      "Training loss : 1.0547673848210548\n",
      "Validation loss : 0.9834411203861236\n",
      "Checkpointing new best model in epoch 28\n",
      "Epoch(29/100)\n",
      "Training loss : 1.051034830662669\n",
      "Validation loss : 0.9736108481884003\n",
      "Checkpointing new best model in epoch 29\n",
      "Epoch(30/100)\n",
      "Training loss : 1.0462581807253313\n",
      "Validation loss : 0.9735201954841614\n",
      "Checkpointing new best model in epoch 30\n",
      "Epoch(31/100)\n",
      "Training loss : 1.046023398029561\n",
      "Validation loss : 0.9730692923069\n",
      "Checkpointing new best model in epoch 31\n",
      "Epoch(32/100)\n",
      "Training loss : 1.0365973741424328\n",
      "Validation loss : 0.9807133316993714\n",
      "Epoch(33/100)\n",
      "Training loss : 1.0381097933467553\n",
      "Validation loss : 0.9696150064468384\n",
      "Checkpointing new best model in epoch 33\n",
      "Epoch(34/100)\n",
      "Training loss : 1.0338433245006873\n",
      "Validation loss : 0.9687857508659363\n",
      "Checkpointing new best model in epoch 34\n",
      "Epoch(35/100)\n",
      "Training loss : 1.0292059602786083\n",
      "Validation loss : 0.9805800676345825\n",
      "Epoch(36/100)\n",
      "Training loss : 1.026810611997332\n",
      "Validation loss : 0.9781045317649841\n",
      "Epoch(37/100)\n",
      "Training loss : 1.0272745964478474\n",
      "Validation loss : 0.9584695935249329\n",
      "Checkpointing new best model in epoch 37\n",
      "Epoch(38/100)\n",
      "Training loss : 1.020941547593292\n",
      "Validation loss : 0.9689154386520386\n",
      "Epoch(39/100)\n",
      "Training loss : 1.0177643262610143\n",
      "Validation loss : 0.9608035445213318\n",
      "Epoch(40/100)\n",
      "Training loss : 1.0135098768740285\n",
      "Validation loss : 0.9571500062942505\n",
      "Checkpointing new best model in epoch 40\n",
      "Epoch(41/100)\n",
      "Training loss : 1.0123514861476666\n",
      "Validation loss : 0.9530621349811554\n",
      "Checkpointing new best model in epoch 41\n",
      "Epoch(42/100)\n",
      "Training loss : 1.010230801543411\n",
      "Validation loss : 0.9649668753147125\n",
      "Epoch(43/100)\n",
      "Training loss : 1.005509116211716\n",
      "Validation loss : 0.9568696677684784\n",
      "Epoch(44/100)\n",
      "Training loss : 1.0054317426924804\n",
      "Validation loss : 0.9496608316898346\n",
      "Checkpointing new best model in epoch 44\n",
      "Epoch(45/100)\n",
      "Training loss : 1.003000584183907\n",
      "Validation loss : 0.9497503101825714\n",
      "Epoch(46/100)\n",
      "Training loss : 0.9978106733487577\n",
      "Validation loss : 0.9482264757156372\n",
      "Checkpointing new best model in epoch 46\n",
      "Epoch(47/100)\n",
      "Training loss : 0.9944355883160416\n",
      "Validation loss : 0.9665032207965851\n",
      "Epoch(48/100)\n",
      "Training loss : 0.9946101082831013\n",
      "Validation loss : 0.9562532126903533\n",
      "Epoch(49/100)\n",
      "Training loss : 0.9958936432186438\n",
      "Validation loss : 0.9792128682136536\n",
      "Epoch(50/100)\n",
      "Training loss : 0.9958377279797379\n",
      "Validation loss : 0.9488939046859741\n",
      "Early stopped training at epoch 50\n",
      "\n",
      "Final, best val error: 0.9482264757156372\n",
      "Elapsed Time: 16 minutes and 26 seconds\n"
     ]
    }
   ],
   "source": [
    "model = CustomCNNCifar(num_classes=10, batch_norm = batch_norm_var)\n",
    "\n",
    "model = model.to(device)\n",
    "optimizer = Adam(model.parameters())\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "cum_epoch_loss = 0\n",
    "\n",
    "def checkpoint(model, filename):\n",
    "    torch.save(model.state_dict(), filename)\n",
    "\n",
    "best_val = sys.maxsize\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "best_val_e = sys.maxsize\n",
    "best_epoch = 0\n",
    "\n",
    "# Training loop for each fold\n",
    "for e in range(num_epochs):\n",
    "    batch_loss = 0\n",
    "\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    for batch, (inputs, outputs) in enumerate(train_loader, 1):\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = outputs.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(inputs)\n",
    "        loss = criterion(predictions, outputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_loss += loss.item()\n",
    "        #print(f'Epoch({e + 1}/{num_epochs}: Batch number({batch}/{len(train_fold_loader)}) : Batch loss : {loss.item()}')\n",
    "    print(f'Epoch({e + 1}/{num_epochs})')\n",
    "    print(f'Training loss : {batch_loss / len(train_loader)}')\n",
    "    #change device to cpu?\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_val, (inputs, outputs) in enumerate(test_loader, 1):\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = outputs.to(device)\n",
    "\n",
    "            predictions = model(inputs)\n",
    "            loss = criterion(predictions, outputs)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "\n",
    "        print(f'Validation loss : {val_loss / len(test_loader)}')\n",
    "\n",
    "        val_epoch = val_loss / len(test_loader)\n",
    "\n",
    "        #Best model checkpointing\n",
    "        if(val_epoch < best_val):\n",
    "            print(f'Checkpointing new best model in epoch {e+1}')\n",
    "            checkpoint(model, f\"best_model.pkl\")\n",
    "            best_val = val_epoch\n",
    "\n",
    "    #Check val loss of epoch for early stopping\n",
    "    if val_epoch < best_val_e:\n",
    "        best_val_e = val_epoch\n",
    "        best_epoch = e\n",
    "\n",
    "    #Early stopping\n",
    "    if e - best_epoch > early_stop_thresh:\n",
    "        print(f'Early stopped training at epoch {e+1}')\n",
    "        break  # terminate the training loop\n",
    "               \n",
    "print(f'\\nFinal, best val error: {best_val}')\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "minutes = int(elapsed_time // 60)\n",
    "seconds = int(elapsed_time % 60)\n",
    "\n",
    "print(f\"Elapsed Time: {minutes} minutes and {seconds} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6cf4af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch (1/10)\n",
      "Batch (2/10)\n",
      "Batch (3/10)\n",
      "Batch (4/10)\n",
      "Batch (5/10)\n",
      "Batch (6/10)\n",
      "Batch (7/10)\n",
      "Batch (8/10)\n",
      "Batch (9/10)\n",
      "Batch (10/10)\n",
      "Accuracy of the model on 10000 test images: 67.11% \n"
     ]
    }
   ],
   "source": [
    "model.to('cpu')\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    num_correct = 0\n",
    "    total = 0\n",
    "\n",
    "    #set_trace()\n",
    "    for batch, (images, labels) in enumerate(test_loader,1):\n",
    "\n",
    "        logps = model(images)\n",
    "        output = torch.exp(logps)\n",
    "\n",
    "        pred = torch.argmax(output, 1)\n",
    "        total += labels.size(0)\n",
    "        num_correct += (pred == labels).sum().item()\n",
    "        print(f'Batch ({batch}/{len(test_loader)})')\n",
    "\n",
    "        # if batch == 5:\n",
    "         # break\n",
    "\n",
    "    print(f'Accuracy of the model on {total} test images: {num_correct * 100 / total}% ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bbe4c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
